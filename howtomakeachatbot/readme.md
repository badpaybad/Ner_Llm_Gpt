# overview

User send some text 
System response text 

We use stacks: Python, Mongodb, Javascript, Html, css

# how we do system generate text to user

base keywords:

                - KB: knowledge base 
                - RAG: retrieval-augmented generation
                - LLM: lagger language model
                - DB vector: Database eg: mongodb, to store text vector 
                - User prompt: text from user
                - System prompt: text provide along side with User prompt
                - Assitance prompt: text generated by LLM
                - LLM Context: whole history User,System, Assitance prompt of an conversation 
                - Embedding: how to get text vector with semantic

base workflow:

                User prompt -> call to system use KB RAG to get System prompt -> feed System prompt to LLM -> Assitance prompt -> system process Assitance prompt -> feed User propmt to LLM -> Assitance prompt -> display text to user

# how we build KB, RAG 

text vector base on https://huggingface.co/Viet-Mistral/Vistral-7B-Chat

                embeding_RAG/main.py

mongodb to store vector

# Embebding and LLM model 

use LLM to generate text base on https://huggingface.co/Viet-Mistral/Vistral-7B-Chat 

                mistralvn/Vistral-7B-Chat
                mistralvn/main.py

# BE (Backend) Expose API to FE (Frontend)

                Python: https://www.w3schools.com/python/
                Fastapi https://fastapi.tiangolo.com/tutorial/
                Mongodb python: https://www.w3schools.com/python/python_mongodb_getstarted.asp 
                Docker db mongo: https://hub.docker.com/_/mongo
                Tool connect mongodb: https://www.mongodb.com/products/tools/compass 
                or
                C# asp.net core

# FE web

                Html, js, css

# FE mobi app

                Flutter

