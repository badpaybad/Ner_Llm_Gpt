# overview

User send some text 
System response text 

We use stacks: Python, Mongodb, Javascript, Html, css

# how we do system generate text to user

base keywords:

                - KB: knowledge base 
                - RAG: retrieval-augmented generation
                - LLM: lagger language model
                - DB vector: Database eg: mongodb, to store text vector 
                - User prompt: text from user
                - System prompt: text provide along side with User prompt
                - Assitance prompt: text generated by LLM
                - LLM Context: whole history User,System, Assitance prompt of an conversation 

base workflow:

                User prompt -> call to system use KB RAG to get System prompt -> feed System prompt to LLM -> Assitance prompt -> system process Assitance prompt -> feed User propmt to LLM -> Assitance prompt -> display text to user

# how we build KB, RAG 

text vector

                embeding_RAG/main.py

mongodb to store vector

# Embebding and LLM model 

use LLM to generate text 

                mistralvn/Vistral-7B-Chat
                mistralvn/main.py

# BE (Backend) Expose API to FE (Frontend)

                Fastapi
                or
                C# asp.net core

# FE web

                Html, js, css

# FE mobi app

                Flutter

